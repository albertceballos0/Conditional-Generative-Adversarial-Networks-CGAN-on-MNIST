{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e2fc8d",
   "metadata": {},
   "source": [
    "# Conditional Generative Adversarial Networks (CGAN) on MNIST\n",
    "This notebook implements and trains a Conditional Generative Adversarial Network (CGAN) on the MNIST dataset using Keras.\n",
    "\n",
    "## Introduction\n",
    "A Conditional Generative Adversarial Network (CGAN) is a type of GAN where both the generator and the discriminator are conditioned on additional information. In this case, the generator receives both a random noise vector and a one-hot encoded label as input, allowing it to generate specific images conditioned on the label. The discriminator is also conditioned on the label to determine whether an image is real or fake for a given class.\n",
    "\n",
    "### References:\n",
    "- [1] Radford, Alec, Luke Metz, and Soumith Chintala. *\"Unsupervised representation learning with deep convolutional generative adversarial networks.\"* arXiv preprint arXiv:1511.06434 (2015).\n",
    "- [2] Mirza, Mehdi, and Simon Osindero. *\"Conditional generative adversarial nets.\"* arXiv preprint arXiv:1411.1784 (2014).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29fd715",
   "metadata": {},
   "source": [
    "## Imports tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61a0024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.layers import Activation, Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e7c84",
   "metadata": {},
   "source": [
    "## Model Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70994a5f",
   "metadata": {},
   "source": [
    "### Generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a6637",
   "metadata": {},
   "source": [
    "The generator takes two inputs:\n",
    "- A noise vector `z` (latent space vector).\n",
    "- A one-hot encoded label that specifies the class of the generated image.\n",
    "\n",
    "The noise vector and the label are concatenated, and the generator produces an image conditioned on the label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc728cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(inputs, labels, image_size):\n",
    "    \"\"\"Build a Generator Model\n",
    "\n",
    "    Inputs are concatenated before Dense layer.\n",
    "    Stack of BN-ReLU-Conv2DTranpose to generate fake images.\n",
    "    Output activation is sigmoid instead of tanh in orig DCGAN.\n",
    "    Sigmoid converges easily.\n",
    "\n",
    "    Arguments:\n",
    "        inputs (Layer): Input layer of the generator (the z-vector)\n",
    "        labels (Layer): Input layer for one-hot vector to condition\n",
    "            the inputs\n",
    "        image_size: Target size of one side (assuming square image)\n",
    "\n",
    "    Returns:\n",
    "        generator (Model): Generator Model\n",
    "    \"\"\"\n",
    "    image_resize = image_size // 4\n",
    "    # network parameters\n",
    "    kernel_size = 5\n",
    "    layer_filters = [128, 64, 32, 1]\n",
    "\n",
    "    x = concatenate([inputs, labels], axis=1)\n",
    "    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
    "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
    "\n",
    "    for filters in layer_filters:\n",
    "        # first two convolution layers use strides = 2\n",
    "        # the last two use strides = 1\n",
    "        if filters > layer_filters[-2]:\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=strides,\n",
    "                            padding='same')(x)\n",
    "\n",
    "    x = Activation('sigmoid')(x)\n",
    "    # input is conditioned by labels\n",
    "    generator = Model([inputs, labels], x, name='generator')\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b08cc7",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6755c0",
   "metadata": {},
   "source": [
    "The discriminator takes two inputs:\n",
    "- An image (either real or fake).\n",
    "- A one-hot encoded label.\n",
    "\n",
    "The discriminator evaluates whether the image is real or fake, conditioned on the label.\n",
    "\n",
    "Both models use convolutional layers to handle image data. The generator uses transposed convolutions to upsample the noise vector into an image, while the discriminator uses regular convolutions to classify the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706497dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(inputs, labels, image_size):\n",
    "    \"\"\"Build a Discriminator Model\n",
    "\n",
    "    Inputs are concatenated after Dense layer.\n",
    "    Stack of LeakyReLU-Conv2D to discriminate real from fake.\n",
    "    The network does not converge with BN so it is not used here\n",
    "    unlike in DCGAN paper.\n",
    "\n",
    "    Arguments:\n",
    "        inputs (Layer): Input layer of the discriminator (the image)\n",
    "        labels (Layer): Input layer for one-hot vector to condition\n",
    "            the inputs\n",
    "        image_size: Target size of one side (assuming square image)\n",
    "\n",
    "    Returns:\n",
    "        discriminator (Model): Discriminator Model\n",
    "    \"\"\"\n",
    "    kernel_size = 5\n",
    "    layer_filters = [32, 64, 128, 256]\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    y = Dense(image_size * image_size)(labels)\n",
    "    y = Reshape((image_size, image_size, 1))(y)\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    for filters in layer_filters:\n",
    "        # first 3 convolution layers use strides = 2\n",
    "        # last one uses strides = 1\n",
    "        if filters == layer_filters[-1]:\n",
    "            strides = 1\n",
    "        else:\n",
    "            strides = 2\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    # input is conditioned by labels\n",
    "    discriminator = Model([inputs, labels], x, name='discriminator')\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33f205",
   "metadata": {},
   "source": [
    "## Training Process\n",
    "The CGAN training alternates between updating the discriminator and the adversarial model (generator + discriminator).\n",
    "\n",
    "1. **Discriminator training**: \n",
    "   - Real images are paired with their corresponding labels.\n",
    "   - Fake images are generated by the generator, conditioned on random labels.\n",
    "   - The discriminator is trained to distinguish real images from fake images for each label.\n",
    "\n",
    "2. **Generator (Adversarial) training**:\n",
    "   - The generator aims to produce images that are classified as real by the discriminator.\n",
    "   - The discriminator weights are frozen during adversarial training, allowing only the generator to update.\n",
    "\n",
    "This process continues for several iterations until the generator can produce realistic images conditioned on the input labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1b510",
   "metadata": {},
   "source": [
    "![](architecture.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48055c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator,\n",
    "                noise_input,\n",
    "                noise_class,\n",
    "                show=False,\n",
    "                step=0,\n",
    "                model_name=\"gan\"):\n",
    "    \"\"\"Generate fake images and plot them\n",
    "\n",
    "    For visualization purposes, generate fake images\n",
    "    then plot them in a square grid\n",
    "\n",
    "    Arguments:\n",
    "        generator (Model): The Generator Model for fake images generation\n",
    "        noise_input (ndarray): Array of z-vectors\n",
    "        show (bool): Whether to show plot or not\n",
    "        step (int): Appended to filename of the save images\n",
    "        model_name (string): Model name\n",
    "\n",
    "    \"\"\"\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict([noise_input, noise_class])\n",
    "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30caa08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, data, params):\n",
    "    \"\"\"Train the Discriminator and Adversarial Networks\n",
    "\n",
    "    Alternately train Discriminator and Adversarial networks by batch.\n",
    "    Discriminator is trained first with properly labelled real and fake images.\n",
    "    Adversarial is trained next with fake images pretending to be real.\n",
    "    Discriminator inputs are conditioned by train labels for real images,\n",
    "    and random labels for fake images.\n",
    "    Adversarial inputs are conditioned by random labels.\n",
    "    Generate sample images per save_interval.\n",
    "\n",
    "    Arguments:\n",
    "        models (list): Generator, Discriminator, Adversarial models\n",
    "        data (list): x_train, y_train data\n",
    "        params (list): Network parameters\n",
    "\n",
    "    \"\"\"\n",
    "    # the GAN models\n",
    "    generator, discriminator, adversarial = models\n",
    "    # images and labels\n",
    "    x_train, y_train = data\n",
    "    # network parameters\n",
    "    batch_size, latent_size, train_steps, num_labels, model_name = params\n",
    "    # the generator image is saved every 500 steps\n",
    "    save_interval = 500\n",
    "    # noise vector to see how the generator output evolves during training\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "    # one-hot label the noise will be conditioned to\n",
    "    noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n",
    "    # number of elements in train dataset\n",
    "    train_size = x_train.shape[0]\n",
    "\n",
    "    print(model_name,\n",
    "          \"Labels for generated images: \",\n",
    "          np.argmax(noise_class, axis=1))\n",
    "\n",
    "    for i in range(train_steps):\n",
    "        # train the discriminator for 1 batch\n",
    "        # 1 batch of real (label=1.0) and fake images (label=0.0)\n",
    "        # randomly pick real images from dataset\n",
    "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "        real_images = x_train[rand_indexes]\n",
    "        # corresponding one-hot labels of real images\n",
    "        real_labels = y_train[rand_indexes]\n",
    "        # generate fake images from noise using generator\n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # assign random one-hot labels\n",
    "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
    "                                                          batch_size)]\n",
    "\n",
    "        # generate fake images conditioned on fake labels\n",
    "        fake_images = generator.predict([noise, fake_labels])\n",
    "        # real + fake images = 1 batch of train data\n",
    "        x = np.concatenate((real_images, fake_images))\n",
    "        # real + fake one-hot labels = 1 batch of train one-hot labels\n",
    "        labels = np.concatenate((real_labels, fake_labels))\n",
    "\n",
    "        # label real and fake images\n",
    "        # real images label is 1.0\n",
    "        y = np.ones([2 * batch_size, 1])\n",
    "        # fake images label is 0.0\n",
    "        y[batch_size:, :] = 0.0\n",
    "        # train discriminator network, log the loss and accuracy\n",
    "        loss, acc = discriminator.train_on_batch([x, labels], y)\n",
    "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    "        # train the adversarial network for 1 batch\n",
    "        # 1 batch of fake images conditioned on fake 1-hot labels \n",
    "        # w/ label=1.0\n",
    "        # since the discriminator weights are frozen in \n",
    "        # adversarial network only the generator is trained\n",
    "        # generate noise using uniform distribution        \n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # assign random one-hot labels\n",
    "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
    "                                                          batch_size)]\n",
    "        # label fake images as real or 1.0\n",
    "        y = np.ones([batch_size, 1])\n",
    "        # train the adversarial network \n",
    "        # note that unlike in discriminator training, \n",
    "        # we do not save the fake images in a variable\n",
    "        # the fake images go to the discriminator input\n",
    "        # of the adversarial for classification\n",
    "        # log the loss and accuracy\n",
    "        loss, acc = adversarial.train_on_batch([noise, fake_labels], y)\n",
    "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "        print(log)\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            # plot generator images on a periodic basis\n",
    "            plot_images(generator,\n",
    "                        noise_input=noise_input,\n",
    "                        noise_class=noise_class,\n",
    "                        show=False,\n",
    "                        step=(i + 1),\n",
    "                        model_name=model_name)\n",
    "    \n",
    "    # save the model after training the generator\n",
    "    # the trained generator can be reloaded for \n",
    "    # future MNIST digit generation\n",
    "    generator.save(model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3aff4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_models(trainCGAN = True):\n",
    "    \"\"\"\n",
    "    Build and train the CGAN models using the MNIST dataset.\n",
    "    This function performs the following steps:\n",
    "    1. Loads and preprocesses the MNIST dataset.\n",
    "    2. Defines network parameters such as latent size, batch size, training steps, learning rate, and decay.\n",
    "    3. Builds the discriminator model.\n",
    "    4. Builds the generator model.\n",
    "    5. Constructs the adversarial model by combining the generator and discriminator.\n",
    "    6. Compiles the models with appropriate optimizers and loss functions.\n",
    "    7. Trains the discriminator and adversarial networks.\n",
    "    Additionally, saves the architecture of each model as an image.\n",
    "    \n",
    "    Parameters:\n",
    "    None\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # load MNIST dataset\n",
    "    (x_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "    # reshape data for CNN as (28, 28, 1) and normalize\n",
    "    image_size = x_train.shape[1]\n",
    "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "\n",
    "    num_labels = np.amax(y_train) + 1\n",
    "    y_train = to_categorical(y_train)\n",
    "\n",
    "    model_name = \"cgan_mnist\"\n",
    "    # network parameters\n",
    "    latent_size = 100\n",
    "    batch_size = 64\n",
    "    train_steps = 40000\n",
    "    lr = 2e-4\n",
    "    decay = 6e-8\n",
    "    input_shape = (image_size, image_size, 1)\n",
    "    label_shape = (num_labels, )\n",
    "\n",
    "    # build discriminator model\n",
    "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "    labels = Input(shape=label_shape, name='class_labels')\n",
    "\n",
    "    discriminator = build_discriminator(inputs, labels, image_size)\n",
    "    optimizer = RMSprop(learning_rate=lr, weight_decay=decay)\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "    discriminator.summary()\n",
    "    \n",
    "    # Save discriminator architecture as an image\n",
    "    plot_model(discriminator, to_file='architecture/discriminator_architecture.png', show_shapes=True)\n",
    "\n",
    "    # build generator model\n",
    "    input_shape = (latent_size, )\n",
    "    inputs = Input(shape=input_shape, name='z_input')\n",
    "    generator = build_generator(inputs, labels, image_size)\n",
    "    generator.summary()\n",
    "    \n",
    "    # Save generator architecture as an image\n",
    "    plot_model(generator, to_file='architecture/generator_architecture.png', show_shapes=True)\n",
    "\n",
    "    # build adversarial model = generator + discriminator\n",
    "    optimizer = RMSprop(learning_rate=lr*0.5, weight_decay=decay*0.5)\n",
    "    discriminator.trainable = False\n",
    "    outputs = discriminator([generator([inputs, labels]), labels])\n",
    "    adversarial = Model([inputs, labels],\n",
    "                        outputs,\n",
    "                        name=model_name)\n",
    "    adversarial.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['accuracy'])\n",
    "    adversarial.summary()\n",
    "    \n",
    "    # Save adversarial architecture as an image\n",
    "    plot_model(adversarial, to_file='architecture/adversarial_architecture.png', show_shapes=True)\n",
    "\n",
    "    # train discriminator and adversarial networks\n",
    "    models = (generator, discriminator, adversarial)\n",
    "    data = (x_train, y_train)\n",
    "    params = (batch_size, latent_size, train_steps, num_labels, model_name)\n",
    "    if trainCGAN: train(models, data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b47b5c",
   "metadata": {},
   "source": [
    "## Code Breakdown\n",
    "The code is structured into several key components:\n",
    "\n",
    "1. **`build_generator`**: \n",
    "   - This function defines the architecture of the generator model.\n",
    "   - The input is a latent space vector concatenated with a one-hot label, and the output is a generated image.\n",
    "\n",
    "2. **`build_discriminator`**:\n",
    "   - This function defines the architecture of the discriminator.\n",
    "   - The input is an image concatenated with a one-hot label, and the output is a classification score (real/fake).\n",
    "\n",
    "3. **`train`**:\n",
    "   - This function implements the training loop for both the generator and discriminator. It alternates between updating the discriminator and adversarial model.\n",
    "\n",
    "4. **`plot_images`**:\n",
    "   - This utility function generates and plots fake images produced by the generator during training, helping visualize the model's progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad7e95",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8865de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(generator, class_label=None):\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "    step = 0\n",
    "    if class_label is None:\n",
    "        num_labels = 10\n",
    "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\n",
    "    else:\n",
    "        noise_class = np.zeros((16, 10))\n",
    "        noise_class[:,class_label] = 1\n",
    "        step = class_label\n",
    "\n",
    "    plot_images(generator,\n",
    "                noise_input=noise_input,\n",
    "                noise_class=noise_class,\n",
    "                show=True,\n",
    "                step=step,\n",
    "                model_name=\"test_outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad50cd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " class_labels (InputLayer)   [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 784)                  8624      ['class_labels[0][0]']        \n",
      "                                                                                                  \n",
      " discriminator_input (Input  [(None, 28, 28, 1)]          0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)         (None, 28, 28, 1)            0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, 28, 28, 2)            0         ['discriminator_input[0][0]', \n",
      " )                                                                   'reshape_9[0][0]']           \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 28, 28, 2)            0         ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 14, 14, 32)           1632      ['leaky_re_lu_20[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 14, 14, 32)           0         ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 7, 7, 64)             51264     ['leaky_re_lu_21[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 7, 7, 64)             0         ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 4, 4, 128)            204928    ['leaky_re_lu_22[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 4, 4, 128)            0         ['conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 4, 4, 256)            819456    ['leaky_re_lu_23[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 4096)                 0         ['conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1)                    4097      ['flatten_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 1)                    0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1090001 (4.16 MB)\n",
      "Trainable params: 1090001 (4.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " z_input (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " class_labels (InputLayer)   [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 110)                  0         ['z_input[0][0]',             \n",
      " e)                                                                  'class_labels[0][0]']        \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 6272)                 696192    ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)        (None, 7, 7, 128)            0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 7, 7, 128)            512       ['reshape_10[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_16 (Conv2  (None, 14, 14, 128)          409728    ['activation_26[0][0]']       \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 14, 14, 128)          512       ['conv2d_transpose_16[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 14, 14, 128)          0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_17 (Conv2  (None, 28, 28, 64)           204864    ['activation_27[0][0]']       \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 28, 28, 64)           256       ['conv2d_transpose_17[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 28, 28, 64)           0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_18 (Conv2  (None, 28, 28, 32)           51232     ['activation_28[0][0]']       \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 28, 28, 32)           128       ['conv2d_transpose_18[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 28, 28, 32)           0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_transpose_19 (Conv2  (None, 28, 28, 1)            801       ['activation_29[0][0]']       \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 28, 28, 1)            0         ['conv2d_transpose_19[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1364225 (5.20 MB)\n",
      "Trainable params: 1363521 (5.20 MB)\n",
      "Non-trainable params: 704 (2.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"cgan_mnist\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " z_input (InputLayer)        [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " class_labels (InputLayer)   [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " generator (Functional)      (None, 28, 28, 1)            1364225   ['z_input[0][0]',             \n",
      "                                                                     'class_labels[0][0]']        \n",
      "                                                                                                  \n",
      " discriminator (Functional)  (None, 1)                    1090001   ['generator[0][0]',           \n",
      "                                                                     'class_labels[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2454226 (9.36 MB)\n",
      "Trainable params: 1363521 (5.20 MB)\n",
      "Non-trainable params: 1090705 (4.16 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_and_train_models(trainCGAN = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "442146a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 419ms/step\n",
      "test_outputs  labels for generated images:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAAC9CAYAAAAN4MczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABSLUlEQVR4nO19eVRb55n+c+/VLoFAEqtYxGpsMKsB2xgwwThe8O4kTZp1ZpLfdHKakzSTdjKdJtP295szbZY6bTPZ2iRtkiZtGsdLjINXwCvGxmxmxyxiFYvQhnZ9vz9c3TE2trGRcFL0nKOT43Dv1avvPve97/d+7/c+FCGEwAcfFhjou22ADz7cDfiI78OChI/4PixI+Ijvw4KEj/g+LEj4iO/DgoSP+D4sSPiI78OChI/4PixIcGZ7IEVR3rTjjnCzRedvm73At8/mb5u9V8Pn8X1YkPAR34cFCR/x/45BURQCAwMhEonAMMzdNucbhVnH+AsJHA4HUVFRKCgoQFZWFuLj42E0GvHJJ5+goaEBarUadrv9bps5I9LT01FSUoKCggL4+fmBYRhcunQJZ86cwUcffQSXy3W3TZwGpVKJ1NRULFu2DPn5+dBqtfjiiy9QXl4OnU7nte/1Ef8a0DQNsViM3NxcrFu3DmFhYeDz+XA4HCguLoZUKsWFCxfQ1NR0t02dBoqiIBQKsWrVKhQXFyMvLw9isRiEEAQEBIAQghMnTqC3txdOp/NumwuGYaBQKFBUVITc3FxkZ2cjKysLOp0O4+PjGB0dRWVlpdce1LtGfIZhIBAIwOVy2dewy+WCw+GA3W6HzWa7K96Jw+FALpdjy5YtyMvLQ11dHU6ePIn+/n784Ac/QFRUFBQKBVpaWr4RBHKDy+UiKioKmzZtQmpqKvh8PoxGI/h8PkJCQpCSkoLc3FwMDg7eVbspigKXy4W/vz8yMjLw+OOPIyUlBcHBwaAoCjKZDHl5eZiamsLp06dhtVq9YwiZJQB47MPn80lSUhL5zW9+Qy5evEgMBgPR6/VErVaT3bt3k+eee45ERkYShmFueh1v2BsYGEhWr15N9Ho9+eijj0hpaSmhaZpQFEVWr15NPv/8c9LQ0EDi4uJuad/t2DsXm93j2djYSEwmE7FaraSvr48899xzZHBwkExNTZGenh7y85//nEgkEo/ZfKfju379evLGG2+Q8+fPE4PBQJxOJ3tNq9VKampqyKuvvkqUSiWhadqjY+zGvHp8hmGQnJyMvLw8PProo4iOjoZUKoVAIAAACAQCrF69GhkZGbj//vuxa9cunD59Gmq1et5sVCqVyM7OBgCUlZWhqamJffM0NTVBo9GgoKAA//Zv/4Z//dd/9WocOltER0dj9erVUKlUYBgGDQ0NOHXqFDo6OmCz2QAAPB4PAQEBoOm7l8/g8Xj453/+Z+Tn5yM5ORkymQxCoRAulwtWqxWTk5OwWCxQKBTYuHEj4uPj8f3vfx/Dw8Men1PNG/F5PB4yMzNRWFiIoqIiZGRkgMfjTVsEoWkagYGBCAgIgFKpxM6dO0HTNM6dO4euri6v20hRFCIjI5GVlQWHw4Hu7m6MjY2xf9fpdBgaGoLBYMDy5cshEAig1+tnvWjiLZtVKhXy8vIgEAhw7tw5nDp1CjU1NZiYmGAJ43Q6odFo7trklsfjYdmyZSgsLMTSpUsRFBQEDocDg8GAjo4OtLe3Y2BgAFFRUUhJSUFUVBQCAwOxbNkyVFdXY3Bw0KP2zAvxORwOwsPDsWPHDhQXFyM9Pf2Gq35uEnG5XOzcuRMURYFhGHR3d3v9pvF4PKhUKixbtgxGoxFjY2OYmppi/+5wONDV1YWWlhbcc889CAwMhE6ng8Vi8apdt7I5Li4OeXl5cDqd2LdvH86cOYPe3l6IxWLY7XYQQuBwODA8PHzXHlI+n4/169cjLS0NISEhoCgKTqcT3d3dOHDgAPbv34/e3l6UlpZCJpNh0aJFEIlEWLduHTvZ9ajXn21MhDnE9GFhYeTrr78mer2euFyuG36Hw+EgU1NTxGQyTYv5ysvLiVwu93r8GR8fT1599VWi1WrJ7373OxIcHHzdMWKxmBQVFRGr1Up27dpFcnJy7mqMn5KSQl5//XViMBiIVqslxcXFRC6XE4ZhiJ+fH2loaCAmk4kYDAZy5swZEh4efltzE0/ZK5PJyJdffkl0Oh17rwcGBsjOnTtJZGTkNK689dZbbNxvNpvJa6+9RpYtW+bRGN+rAZ/bG61evRorV66EWCxmPb3T6YTNZoPVasXU1BQmJibw//7f/8NLL72E999/n808uBdhcnJyvL4I88Mf/hCbNm2CXq/H66+/jsnJyeuOcTqdsFqtMBqNWLVqFSIjI+9azQrDMPjJT36CnTt3AgDOnj0LtVoNo9EIp9OJqakp/OpXv8LZs2fB5/OxZMkSPPLII0hKSpp3WymKgp+fHzvHcDgc6OvrQ1NTE0ZGRtjjDAYDrFYr+2bi8XhITExEenq6R+3xWqjD5XJRWFiIzMxMZGdnw8/PDwBgtVrZFBWfz2f/X3NzMyoqKthUpsPhAMMw7CvRbDZ7y1QAgFAoxOLFi8Hn89HS0oLu7u4ZX60OhwNTU1PQarUICQmBRCIBRVHzHkLw+XwUFBQgNTUVQUFBMBgMaG5uhl6vnxbXnz59GkuXLkViYiLCwsKQl5eHhoaGaRPf+QBFUeDz+SzxCSGw2+0wmUzT7HBPcsfHx9kUZ0BAAORyuUft8bjH53A48PPzQ3R0NO677z48/PDD2LJlCwghsFgsGB8fx9DQEEwmE4ArXstut7Ox89jYGCwWC+vxCSEwm83o6enxWoxP0zTkcjlkMhlGR0dx+vRpmM3mGcnscDhgNpsxNjYGiUQCPp9/Vzy+QCDA9u3bERQUBJfLhfHxcVy8eBEmk2naOLW1taGmpgaNjY2gaRoZGRmIj49HYGDgvNt8dTKDoihwONf7XYfDgcHBQVy+fBmEEFAUBYFAALFY7FFbPO7xo6KikJeXhxdeeAEJCQkQCAQghMBms6GxsRFtbW0wmUx48MEHweVyQdM0RCIRYmJiwOfzkZ2djZKSEgiFQgCA3W6H0WjE0NCQ17wqn8/HqlWr4OfnhxMnTuD3v//9TY+3Wq1Qq9VYsmQJeDweuFzuvC8KcblcJCcng8/nY2RkBOfOncOf/vSnGZ3D559/ju7ubqxbtw4RERHIz8+HRqPBn//853mz1010N/FpmoZMJrsufCWE4Ny5c5DJZMjJyWEXvHg8nkft8Sjxf/SjH6GgoADJyckIDQ0Fl8uFTqeDWq3Gxx9/jLq6OkRHRyMnJwc0TbOriHq9Hm1tbSgoKEBpaSny8/PZATp9+jQOHz7s1dcyj8dDcXExRCIRrFYr+za6EYxGI44dO4aSkhJwuVxwudx5zey4c/KpqakQCAS4dOkS9uzZc8M34rXEWbFiBcxm87wSn2EYREVFgcvlAriySq/T6WZ0GO7Ve5fLBZqmERQUBKVS6VF7PEJ8DoeDrKws5OXlITU1FaGhoeBwOGhsbERdXR1qampQVVWF4eFhDAwMQKPRYHx8HBRFISIiAsHBwYiOjoZcLkdKSgoCAwNBCMGFCxfw9ddf48SJE16Nod1FaTRNw2q13pLE7noe97numzlfUCgUWLp0KSQSCYArD6JGo7nh8XFxccjJyWH/HRAQgODgYNA0PW95fXeMf3VYePUb4GqoVCqkpqZOC4s8vfA2Z+IzDAN/f3+sW7cOycnJCAkJAU3TmJiYQEVFBQ4dOoSqqiro9XoAwMjICNra2nDu3DkEBQUhMzMTy5cvR0FBAZRKJYRCIRv3HzlyBEePHkVDQ8Ocf+jNQNM0QkJCAEyffM8E9w2MioqCy+Vi49D5RHh4OHJzc9lxmpqauukKcmRkJJKSklhbeTzedYuH3gZFUdO+j6IoiESiGQkdFxeHzMxM9m92u93jb9Q5E18mkyE1NRWPPPIIlEolOBwOTCYT/vSnP+G3v/0tent7ryOS3W7H4OAghoaG0N/fj/b2dshkMkRHR4PD4cBut0Oj0eCjjz7y6qTWDYZhEBkZCZqmQQi55XY7kUiE5ORk6HQ6aDQaaLVar9p3NWiaRkJCAjZu3AgAMJvNGBwcREdHxw3PaWlpwalTp/DEE08AAEwmE/R6/bzOSwghsFqt7NzNXQzo9vruMacoCgqFAtHR0eyDotPppq2gewJzJv7y5cvx05/+FFFRUWAYBmq1GhcuXEBZWRmGh4dv6j15PB62b9+Ohx56CDk5ORAIBDAajbh06RJeeeUVdHd3z0vs7HQ6oVarERAQAKvVetMQgM/nQyKRgMvlor6+ft7LAAQCAYKDgxEbGwsA+PDDD3Hs2LEbzoEoikJRUREee+wx1oPW1dWhoqJivkxm7bjWu9M0DQ6HA5qm2YcwNDQUUqmUJb27YtfTYzynwImmaUilUkRFRYHD4aC5uRlHjx7Fl19+icbGxhvm3t3nbd26FWvWrEFycjJEIhEMBgPOnDmDvXv3orq6etpChjfhcDjQ3t7OlkrPlGZzwx3qxMTEoLq6Gv39/V6372pwOBw2kwRc8d43G6fIyEgsWbIEixYtAgDYbDY0NTXh/Pnz82Yz8L8e/2o7ORzOtJQwTdNYvnw5oqOj2cm4O9Xt6f0Pc/L47vyqOxty7tw5HDlyBCdOnJiREO7jry5CW7ZsGaRSKQYHB9HS0oKDBw+iqqpqXgnldDrR09ODVatWQSQSgcfj3dCDCoVCyOVyhIeHo66u7qaTSm/g2liZx+PNGCe7Y/msrCwkJSUhKCgIADAwMIBLly6hpaVl3mwGroyx0WhEYGAgG94wDIPQ0FAMDw9Dp9MhODgYRUVFiI2NZR9sg8GAlpYWNDY2etSeORE/PDwcwcHBIIRgaGgIf/3rX1FTUzNjPEZRFGJjY5Gfn49Vq1YhJSUFixcvBsMwGBwcxFtvvYW3334ber1+3isI3ak1Qgi4XC6EQiGMRuOMxy5atAgrV64EIQTd3d3zXpbsTvU5nU5wuVwEBgay2R033G+liIgI/PjHP0ZiYiIYhgEhBB9//DHOnj2LiYmJebXb6XRicHAQoaGhrIcXCAQoLCwEh8PBxMQEnnzySWzZsoVdDQeA1tZW1NTUeD7BMduiHsxQEBQcHEyef/55YjabSVlZGVmyZMl1GwcCAgJISkoKefHFF8mXX35JGhsbiVarJXq9ngwNDZEXX3yRREVFEbFYTCiK8timg9u5DofDIUuWLCGXLl0if/nLX0hRUdGMx/H5fPKzn/2MDA0NkYGBARIWFnZbNt/JGF/7oSiKbNmyhVRUVBBCCOns7CT/+q//SjgcDgFAaJomKpWKbN68mXz66adsYaDZbCaNjY0kPj6e8Pn8eR9jLpdLMjMzyfnz58nU1BR7jYmJCdLR0UHq6+uJwWCYVsTocrnI66+/PusCtdug89w2oiQnJyMuLg4ulwtOpxM0TbOeRSgUQqFQICMjA3l5eSgoKEBoaCh4PB6Gh4fxxz/+EcPDw6ipqcHAwMBd3Q7ncrkwOjoKm82GxYsXY/v27aioqLgubo6Li2OL0srKyjA1NTXvNTqEEIyPj7MLfiEhIVi1ahW0Wi3Gx8ehVCqRmJiIpKQkJCUlsXOnjo4O/PrXv8bQ0NC81ui44XA40NnZCbPZPO1e+/v7QyAQwOFwTCtiJH+r5WEYxivFiXMifmhoKFs8JJFIkJCQAA6HA5fLBblczq7S5ufnIz4+HgaDgc36fPTRRxgeHobD4fDID5kLCCEwmUzo7+9HWloa7rnnHmRmZqK9vZ2dkDEMg7y8PERHR8NkMuHYsWPe2w96C2g0GtTV1cFgMEAsFiMtLQ1CoRAjIyOIi4uDSqVCWFgYKIqCTqdDa2srqqqqsHv37rvysAJXxliv10OtVkOlUrHhmTuhAGAa6S0WC/r7+zE8PHzLlfQ7NWhWwAyvlZKSEvLOO+8Qu91ONBoNOX78ODl48CCprKwkGo2GmEwmYrfbicvlIna7nRw+fJj80z/904x17nfy8dRr2P15/PHHyf79+4nZbCYdHR1k1apVJCoqiiiVShIfH0+6urqIwWAgNTU1JD4+/q7uuQ0ODianT5+etnfhWjidTnL48GHy4IMPEqlU+o0Y402bNpHPPvvshvsyXC4XsVgspLOzk7z00ktEKpV6NJxkbZ/1gTN8yfe+9z1SVlZGrFYrMRgMZGhoiAwPDxOtVkucTiexWCxkfHyc1NXVke9+97tEqVQSoVB427H8fN0UsVhMHnzwQXLo0CFit9vJxMQEGRwcJGq1moyPjxOTyUTef/99UlJSctuboD1NfJqmiUKhIEePHiVarXbadfr6+sjx48fJe++9R1QqFeHz+Xc85p4eY4FAQB5//HFy/vz5Ga956tQp8vLLL5PCwkKPz/uuxpxCnWPHjsFgMKC/vx86nQ4TExMQCASQyWSIiIiA0+lEc3Mzzp07xy72fFMbMQHA1NQUampq4HK50NXVhfvuuw8ymQwmkwmNjY04fvw4Tp06hfr6+rvemMnlcmFiYgL/9V//BYVCwZYgEEJgNBphMBig1+sxNDR010KymWC1WnH27FlQFIX169dj7dq1sNvtGBoaQn19Pfbu3Yv29nb09/d7J8T5G+ZE/La2NkxNTWF8fBw6nQ6Tk5MQCASQy+VQKpVwuVy4dOkSamtr7+qG7NmCEIL+/n52v21gYCACAwNhNBpx9uxZlJWVsQ/5NwEulwtHjx6922bcFggh6O3thdFohMViAUVRsNlsUKvVqK6uxvHjx2EwGLye7KDILBn5bWsJ/W2zF/j22fxts/dq+JrG+rAg4SO+DwsSPuL7sCDhI74PCxKzntz64MPfE3we34cFCR/xfViQ8BHfhwUJH/F9WJDwEd+HBQkf8X1YkPAR34cFiVlXZ37bCpK+bfYC3z6bv232Xg2fx/dhQcJHfB8WJHzE92FBwkd8HxYk5lXg2Qfvg6ZpJCYmIjk5GYsXL0ZOTg64XC60Wi2OHj2KkydPslq938T6RJlMhiVLlmDp0qVIS0tDfHw8aJpGX18f3n//fZw5c8Yj+7bnTec2OjoaEomEFVKQSqWQSCTg8XhsL0V3m7nBwUH09PTctU3S7p7/7kZGLpcLFouFbcRE0zSEQiEcDgdsNts3YgM9h8OBSqVCQkIC0tLSsHTpUsTGxiIlJQVcLhd6vR4SiQRKpRIXLlxAS0sLLl++fLfNZuFue7hmzRpkZ2cjJSUFixYtYgU7uru7UVdXhwsXLsDhcMz5ofUq8d2d1QICAlBSUgKVSgWhUMg2n4qMjIS/vz8rEGCz2VBVVYVjx45hz549bIeA+eqyRtM0uFwuxGIxlixZMk2Ha3R0FAaDAcAVaZ2goCBWBE6n07EPwN3yokKhEMXFxXjwwQeRlJTECl24ERQUhE2bNqGkpARlZWX46quvMDg4OG8dqW8FHo+HqKgoPP3001iyZAlkMhmAKz03KYqCv78/srKy8Omnn8Jqtc69Edls+5DgDnqohIWFkaKiIvIf//EfxGQyEafTSVwu101Fnl0uF5mamiI9PT3ke9/7HomPj5+3ni+xsbFk/fr15KWXXiK9vb3EZDIRs9lMTCYTmZycJGazmVgsFmKxWIjdbicGg4GcOHGC7Nq1i2zbto0EBASwPSxv1947tfnqsa6srLxpgyn3+JpMJlJXV0eefPJJ4ufnd9MeQd6y9+qPSCQiOTk5RKPRsGNrsViIWq0mBw8eJJ2dnUSv15PW1lbyxBNPEJVKdXf76swEiqIgl8vx5ptvIiwsDAEBAQgMDIRQKJy24EH+pjxyddtr8jfPw+fzERISgu985zvo6elBb2+vV8MJgUCAjRs3YvPmzUhMTGR1ua7WaBIIBDNK2aSnpyM+Ph733nsvysvL8eWXX+LixYus9NF8QCAQICgoCImJiax2sBs2mw06nQ4Gg4ENzdztX/75n/8Z3d3dqK+vx+jo6LzZ6waPx8MPfvADpKenIyEhgZUg1ev16O7uxmeffYb6+nokJiYiNzcX27Ztw/bt29HT04Oenp45fbdHic8wDGJiYpCXl4fCwkJIpVJwuVwwDMPqw7rlfwYHBzE1NQWn08k2nA0ICMDixYsRHR2NgIAAJCQkID4+Hk1NTVCr1Z40lbVXLpcjPj4eW7duxYoVK1jR5msx0yolTdOQSCSQSCQIDg6Gw+HAyMgITCbTvAkviEQipKamoqSkBAEBAayckd1uh1arxf79+6HRaDA1NQWHwwGn04mMjAykpKQgISEB69evh1arxcTExLyGlFKpFDt27MCGDRsQHx8PmUwGi8WC1tZWXLp0CfX19Th+/DgGBwfhcDgQGhoKkUiElJQUVkJoLuGOR4mvUCiQn5+PJ598klWltlqt0Ov1mJiYwNjYGGpqanDq1Cm2j77FYoHdbgdFUYiLi8MDDzyAdevWIT09HTKZDElJSUhMTPQ48SmKglgsxuLFi7FhwwZs3bp1mhgZIYQlisvlYrv20jTNkuvqh4GmaSQnJ2PFihXQaDTzQnyaphEVFYX169fjH/7hHyAQCOByuWAwGDA2Noa2tja8/PLLGB4eZju/0TSNjRs3YsuWLUhOTsa2bdtQU1OD5uZmr6vHu8Hj8aBUKvGzn/0MCoUCNE3DbDajs7MTu3fvxuHDh1FXVweHwwGKoli7aJqGUqmEn5/fnInvsRifpmny5ptvktbWVuJ0OgkhhDgcDnLkyBHy5JNPEpqmCUVRt+yFyOFwSHp6Ojl27BixWq3k9OnT5MUXX5zxvLnYKxAIyPr168nvf/97Yjabp53rdDqJTqcj9fX15MiRI2Tv3r2ksrKSXL58mWi1WrZXqNVqZX+rG/v27SNPPPGE12N8mqZJREQE2bNnDxkYGGDnTqOjo+RXv/oVSU9Pv+G5KpWKPPnkk8ThcBCtVkueffZZEhkZOS8xPsMwJC4ujjz66KPEZrOxNlRWVpKQkJAZG/G+8MILpLGxkRBCyOjoKPnOd75zw4a9s4XHdG5zc3ORmpqK8PBwVsyro6MDFRUV2L9//6x7TTocDgwNDeGzzz7DsmXLEB4ejtjYWIhEIo/1UuTz+dixYwfuv/9+pKamTouLe3t7UVNTg9deew16vX5aL3mZTMbG+iaTCQqFAk8//TQ2btzIen8ul3tdnO1pCIVCKJVKvPjii8jJyYFMJsP4+Dh+85vfoKamBh0dHTeVUrJarZicnMTY2BgCAgIgk8kglUq9Ek5eDYZh8OSTT6KoqAjZ2dlwOBzo6OhAeXk5Dh48iPHx8evCLYqiMDY2hv7+fixZsgQvvfQSampq5hyWeYT4DMMgLi4OcrkcAoEANpsNzc3N2LNnDyoqKm5bqtFgMODs2bMYHx8Hn89HYGAgRCKRx3q7E0Kg0+kgk8kQGBg4bXLd2NiIzz77DHV1ddNITwjBwMAAK3xhs9kQGRmJ8fFxWK1Wtse7y+XyekNZpVLJSioFBgZiZGQE58+fR1lZGXp6emAwGG66BmI2m6HX62E0GiGXy1nyexM8Hg9Lly5FSUkJsrKyEBgYiH379qG6uhq1tbVoamqaMXShKIp1Ju77Mz4+Pmd7PEJ8dybH7Q3NZjMOHz6MDz744I7UTqamptDc3Ay1Wo24uDhIpVLWq3mK+MPDw2AYZpoqud1uR1NTE/bs2TOjzdfGwP7+/mzTUzfxORyOVxQ83BAKhVi0aBE7KdTpdKitrcWePXtw4cKFWY2PxWKByWSCzWYDRVHw8/ODVCr1ms0ikQihoaFYt24dVq5ciYCAAHYl9tSpUzd9k9M0jcDAQCgUCjidTmg0Go9IwHqE+C6XC93d3bBarXC5XJicnMSuXbug0Wju+JXkcrlw8uRJBAQEICgoCMuXL0dXV9ecval7Uvv0008jLi6OXaQCrqiua7XaWdlMURQ2btyIxYsXT7tGZmYmNBoN3nrrrTnZeSNkZWVh06ZN2Lp1KwDgd7/7Hfbt24eTJ0/O+hoMw0AoFLIJCEKIV99ShYWF+Jd/+ResXr0aIpEIjY2N+Prrr1FVVXXL1XmpVIqYmBioVCoYjUaYTCaPqOh4hPjumFmhUMDhcLBK1HMx0OVy4fDhw8jMzERgYCD6+vo84u2XLFmCzZs3o7S0FAEBAWyY43Q68cwzz+DMmTOzug4hBM3NzUhLS0N0dDSCg4MBAGfPnkVVVdWc7ZwJDMMgOzsbixYtAkVR0Gg02LdvH+rq6m7rOv7+/pDJZOByuaz+18jIiFdsBq6Mrd1uh0gkwsWLF/HnP/8ZH3300axWjbOyshAZGQmj0YiysjLodLpvBvF5PB7kcjnS09MhFosxPj6Ojo6OOS84URSFxMREBAQEwOl0snKccwFN04iJiUFpaSkCAwPZkMRut6O+vh6tra2zno8wDMPG91enNd0pT0/DPY/KyclBTEwMrFYrysvLoVarbxgquL35tddJSUnBypUrweVyWX0Db8l/utdKEhISAADNzc1obW2FRqO56f3kcrkICwvDmjVrEBkZCZ1Oh+PHj3tMuG7Od0goFCI0NBRxcXEQCASYmJhAc3OzR0haUFCAsLAwjxGfw+EgPDwcy5cvnxaHW61WHDt2DJOTk7MKcxiGgUQigVQqZQWh3eByudP+7SlwOBzk5OQgPT0d4eHhMJvN+PLLL6HVam9rXGQyGZYtW4a8vDxwOByMjIxgeHgYWq3W4zYDV94ukZGRSExMhM1mQ319PXp7e28ZWgmFQqSlpWH16tXw9/eHWq3G2bNnPSYWOGePL5VKER8fzxJJo9F4RIyXpmmsXr0acrkc7e3tt/QQs4G7MvRajzw1NYU//OEPs7r5NE3Dz88P6enp+K//+i9ERESwMb7T6URXVxdaW1vnZOdMEAgEeOqpp6BUKgEAk5OTOHDgwE2JMJO337BhA/Lz8xEXFweapnH06FE0Nzd7jfjZ2dlYsmQJKIqCWq3GgQMHZjU+CoUCjz76KBYtWoSqqirs378fXV1dHrPLIzE+uWoVc3h4GBcvXpzT9SQSCZKTk9mJ0K1m/rOFxWK5bjLldDphNptx+fLlG75G3fVEAoEABQUFKCkpwc6dO6FQKNiSDEIIJicn0dbWhvb29jnbejVomoZAIEBYWBi4XC5GRkZQV1d3W4kDPz8/5OTk4LHHHsOSJUsgEomg1Wqxb98+9PX1edReNyiKwoYNG5CdnY2pqSm88847twwlaZrG9u3bcd9992HdunUwGo2oqKhAWVmZR22bM/FFIhHCw8PZenq73T6nOnq5XI5Fixbhu9/9Lng8Hurq6nD27FmPZB3cQtRXP6hOp5Mtm7jWQ6pUKqhUKoSGhsJsNsPPzw95eXlYuXIl+5uBK3MEnU6Hd999F2fOnPF4vOzv78+mdWmaRk9PDyorK2f1BqQoChEREUhJScEjjzyCxYsXw8/PDxqNBgcPHkRzc7NXCuooikJQUBBiY2MRHBwMu92OS5cu3TQVSVEUiouLsXbtWmRnZwMADhw4gNra2tteC7oV5kx89wKTm/gOh+OO4zA/Pz8kJCQgLy8PmzZtwtTUFBoaGtDY2DhXM6fBXXsDgBVvTklJYQu1aJqGWCxmV6NjY2NhMBgglUqxZMkSxMTEsELWNpsNWq0W9fX1+Pjjj9Hf34+pqSmP2hsQEIBFixZBIpGwC2nnzp275XkMwyAiIgLLli1DYWEhNm3aBKFQiNHRUTQ1NWH37t0YHBz0SuUrwzBISEhAeHg4xGIxtFotenp6ZvwugUAAoVAIPz8/bNq0CStWrIBCoUBDQwP279+P9vZ2j+Tur8aciW+1WjExMcFmEOx2+x0VOzEMgxUrVmDr1q3Iz89HaGgoysrK0NDQgIGBgbmaycLpdMJms7FxOZ/PR0xMDMrKyrB//352p1J2dja77c1dLOXv7w+apllP73K52MK7//t//y+6urq8otSuUCiQlpYGHo8Hk8kEjUZz091TFEWBw+FAKpXi3//937F8+XLExsZCIpHAZrNh3759+Pzzz3H06FGvbULh8/nYvn07+2bU6XTo6em5LpzkcDiIi4tDeno68vLy8PDDD4PL5aKxsRGPPfYYuru7vVM1OtuiHtyg6CgkJISUlpYSu91OnE4nKS8vJzt37rytYquQkBDy1FNPkSNHjhC1Wk20Wi2pq6sja9euJUFBQXe06eBG52zZsoU0NDSwiutuOJ1OYjKZiMFgICaTiS1Ac3+u3TzjdDrJ2NgY+eUvf0mWL19OuFzuLX/rnY5xWFgY2bZtG3E6ncRms5H9+/eT0tLSacdQFEXEYjFZtWoVefTRR8lPf/pTcujQIaLVaonNZiNOp5PY7XbyzDPPkJSUFMLn82d1f+7EXgAkICCANDY2kqmpKTI2NkaOHj06rbCMoigiEonIK6+8QioqKkhvby8xGAzEYDCQV199laSkpNy2cvxt0HnuRWpGoxF9fX2wWCwQiURITEzEli1b8PXXX2NqamrG2Nw9UQwJCUFMTAxSU1Oxc+dOJCQkgGEY9PT04IMPPkBTU5PH48/Ozk588sknuPfee5GZmcmWHdA0DZFIdNNzyd9KlaempjA4OIgTJ07g5MmTN3yFewo6nQ4dHR2w2WzgcrlISUnBgw8+iBMnTsDlcrGhjEwmQ2RkJKvPGxYWBj8/P4yNjeHy5cs4fPgwDh06hIGBAa/vZ3bvVXBP/AkhbDl3QEAAYmNj8dBDD6GkpAShoaEQCATQarX44IMPcPjwYe95+r9hzsS3WCzQaDQYGRlBREQEwsPDkZeXh9zcXHR0dMBsNrM14lKpFH5+fuwnNjYWqampyMjIwIoVK2A2m9HR0YFTp07hwIED0+rIPYX+/n58/fXXbGrTvelFLBZP2w3mBvnbcr7VaoXRaIRer4dGo0FtbS3KysrQ0tKCyclJj9p4LcxmM0ZGRtDe3o74+HhERkbinnvuQUFBAVwuF9asWYNt27ax9VLucMzhcECtVqOpqQnV1dX49NNP0dPTMy8bTiiKAsMw7H/FYjHS0tLA4XAQFhaGlJQUPP744/Dz84PZbMbw8DDOnDmDTz75BGq12ut7Azwi8CyRSPDKK69g+/btCA4OhtPpxNDQEP7nf/4Hw8PDMJvNOH36NFavXo2VK1ciPT0dIpEIcrkc/v7+EIvFcLlcaGxsxLvvvouvvvpqViWyNzP9Zva6N3CkpqYiNzcXBQUFSE9PZ3P8buK4d4eZzWb09/ejrq4OHR0daG5uRnl5OUwm023FyLc69mY28/l8PPjgg/jxj3+M2NhY0DQNl8s14yqx+800Pj6O1157DUeOHEFzc/MdrXre6RjL5XLU1tYiNDQULpcLer0eAwMDSEhImLbhx+Vyobq6GgcOHMBrr702583vsz3XI8RnGAZLly7FO++8g7S0NPD5fLYlh5s8drsdQqGQzXu7vau7pcjvfvc77NmzB/39/dDr9bPy9Hd6U4D/7QDB5/Ph7++PlJQU9oEUi8VYu3Yt6urq0NfXh8uXL+PMmTMwm82YmpqC2Wy+bdLfyt5b2UxRFEJDQ/Hhhx8iNzf3htWULpcLPT09qKmpweuvv46WlhaYzeY7nnTf6RjLZDKcPHkSKpVqWsn21dk0m82Gt99+G1999RVOnTrlES8/r8R3Zzw2bNiADRs2YOPGjezG4auNubru3el0oq+vDxcuXEB1dTUOHjyI3t5e9mGZDeZC/KuPYxgGgYGBkMlk4HA44HA4iIiIwPj4OIxGI4xGI1tp6l4LuJMQbC7EB654/aKiImRlZSEnJwcbN24EADbTc+zYMfT19aGvrw/d3d1oaGiA0WicU7h4p2MsEAjwwAMP4J/+6Z+QlJTE1kY5HA60tLSgpqYG58+fR01NDXp7ez222X22xPfYyq1Op8OhQ4dA0zRCQkKQkJDA7qd0E6Wrq4vdYG61WtHV1YXTp0+jpqYGbW1tnjDljmx3OBwYHR2dNvj19fV3xZ6bwWq14ujRo+jp6cHg4CDrSY1GIwYHB7Fv3z50d3djdHQUOp3urtv61VdfITIyEmq1mt0gbrfbUVdXhxMnTuDMmTOYnJz0+sadmeARj381QkJCkJSUhDVr1uDee+8Fn8+HyWSCxWLBT37yE1y+fBlGo5FdLZ0LPOHx5xNz9fh3A39vY+yGx4nvTg0yDAMO539fKO6YzuVyeWzR5O/tpnzbbP622Xs1PE78+cTf2035ttn8bbP3avjahPuwIOEjvg8LErMOdXzw4e8JPo/vw4KEj/g+LEj4iO/DgoSP+D4sSPiI78OChI/4PixIzLpI7du2Svdtsxf49tn8bbP3avg8vg8LEj7i+7Ag4SO+DwsSPuL7sCDhVWXzbzvcnciSkpKwfv16LFq0CBaLBX19fdizZw/OnDnj8Q5fdwIOhwO5XI6HHnoI+fn5EAgEGB8fx+7du6FWq2EwGGAwGDAyMjJvkp7fdMwr8cViMaRSKYKDg5GamgqKojA4OAi1Wo3u7m7YbLZvhLy8G1lZWUhPT0dmZiZWr17N9qUfHBwETdPQ6XS4fPmy19uL3AohISFIT09HaWkpli1bBh6Px249HBkZgcFgwOTkJLq7u9HX14eBgYF51bW9EdzNcN3C0/OJeSM+RVGIjIxEcnIycnNz8cwzz4CmaZw4cQKHDh3CF198gZGRkTl1BPA0tm3bhnvuuQdLly5lWw7yeDwkJiYiOjoaIyMj2Ldvn0d6998peDwelixZgq1bt6KgoIDd9eZuR+Lur2MymdDZ2YmKigqUl5ejrq4OWq32rux3Ba68TYODgxEUFASj0cg6D3fzKfdeaPfmfvfHY5htyzXcZiu3qz8Mw5DQ0FBSVlZGhoaGiMPhIFNTU2R4eJjodDpis9mI2WwmL774IklPTyc8Hs+r7e1m+3nllVdIXV3ddVq2hBDicrlIZ2cneeqpp0hgYKBH2tvdiY1FRUXknXfeITqdjr2O1WolExMT5NKlS2R0dJSYTCa2xaPD4SB1dXVk165dRKlU3lJ32BtjTFEUUalUZHJyktjtdjI2Nka6urrI0NAQ6ejoIK2traS6uprs2rWLvPjii2THjh0kNTWVcDicOY+xG173+DRNIzg4GL/4xS+QlZUFDoeD+vp6/PSnP4Xdbse9996L4uJixMfH48knn0Rubi4qKyvxq1/9ytum3RDudik5OTmIjo5m+/8YjUbw+XxW3VGpVGLTpk2gKArvvPPOvNvo5+eHrKwsJCYmQiwWs39zi3P8+te/RmhoKAoLC7Fy5UrExMSAy+UiISEBhBDU1dXhs88+m/d5SlRUFPLy8uDn5weKotjeRn5+fpBIJACA8PBwREVFwW63s10kjh49infffdcjOlheJ75cLkdycjLy8/NBCEFtbS2OHTuGkydPst2VBwcHERkZiQceeAAZGRkwGAxsp7C7AT6fj6VLl7Itru12O8bGxnDw4EHw+XxEREQgLy8PfD4fycnJ0Gg0+OSTT2A0GufNRoFAwKqbxMTEsI2aLBYLuru7cebMGdTW1kIsFmNychIDAwMoLi5GVlYWRCIRoqKisHHjRlRUVGB4eHjeyB8VFYX8/HyUlpaCpmm0tLSw85GYmBgcP34c/v7+UCqViIuLg0gkAiEEYWFh4PP5MBqNOHz4MNrb2+fED68S3y22VlhYiMjISJw7dw67d+/G559/zoonHD16FMePH4dAIEB+fj5iY2OhUqnA5XK93th0JnA4HAQEBKCkpASBgYGs0smFCxfw6quvgsPhIDMzE3FxcQgPD0d0dDSWLl2KkJCQGzbJ9TQoioJEIsFTTz2F7Oxs1ksCgF6vR2NjIyoqKqDVajE2Nga1Wo3z58/DYDBg8eLF4HK5kMlk2Lx5M/74xz/CbDbPG/EzMjJQWlqKHTt2QKfToaKiAnq9Hv7+/hAIBHjjjTcQFhaG5cuXY8OGDYiMjASfz4dEIsGqVaugUqmg1WrR19c3Nx2C2cZEuINYLjw8nPznf/4n0Wq1RK/Xk5KSEiKXy28Y93355ZdkcHCQXLhwgcTFxRGapuc9/lSpVOSxxx4jVquVuFwu0tzcTH7zm99MawMulUrJpk2byPj4OHG5XKStrY088MADt5ybeGqMRSIRSUtLIw6HY9r5LpeL1NbWkv/zf/4PEQqF153H4XBIW1sbsVqt7Dk1NTVk/fr1N4z1PTnGQqGQvPXWW6S1tZWMjY2RZ599lhQXF5Of/exn5MKFC2RsbIxs27aNrFq1iqxatYqUlJSQ9957jxw5coS0trYSl8tFLBYLeemll0hSUtI3M8bn8Xh44YUXUFRUBLvdjvfeew/Nzc037fA1PDwMk8kEsViM9PR0qNXqeU1zuZVYtmzZAi6Xi4mJCXz55Zd45513pjW/slqt6O7uxuTkJCQSCXg8HsLCwrwi83kt3LpSL7zwwrTvs9vt6OzsxOuvv45z587NGAM7nU588MEH2LlzJ7KysgAA8fHxiI6OZpXjvQWhUIitW7eisLAQISEh6O/vZ1Ubh4eH0dvbi5dffhkmkwk9PT3QarWgaRqtra1ISUlBQUEBnn32WfB4PKSmpuLy5ctzEtnzCvH5fD5WrFiB3NxciEQiNDQ04MCBA5iYmLjppGRgYABGo5HN7ZJ5TBFyOBwUFxcjLy8PKpUKNpsNX3zxBY4fP47+/v5px9rtdoyMjKCrqwt+fn7g8XhQKpXzQvy4uDikpKQgMTFxWnWk1WpFS0sLmpqaMDw8PGPqjxCC48ePIzc3F5mZmazKO5/Pn9b8y9MQCoUIDw9HSUkJQkJCMDg4iGPHjmF4eBg2mw29vb0AgD/96U9QqVQYGxvD+Pg4TCYTDAYDHA4HBAIBuru7kZiYCJVKhfj4+DnZ5PE7xTAMpFIptm7diri4OExMTODo0aM4ceLELbvhqtVq6PV6OBwOGI3GeSM+wzAIDw/HmjVrkJqaCoZh0NfXh/fffx/V1dXXxe1Op5MVsp6cnASPx0NoaOi8ED87OxtJSUnTiOpyuWA2m3H+/HkMDQ3BZDLdcK5RW1s7TcWcw+FMkzfyNNwicBkZGSgoKACPx0NTUxP27dvHtgQ3Go1ob2/H22+/jczMTGRnZyM6Opq9xtDQEBobG3Hx4kU4nU4EBwcjLCxsTnZ5/E4FBwcjNzcXjz76KEQiEWpqavDpp5/ectJHCEFXVxd0Oh1EItG0TIW3IZVK8cYbbyA1NRUSiQRjY2N4/vnn0dTUBIPBcEN7bTYbK3g3OTk5Lw9qQUEBMjMzp6Uv3avJH3/8McbHx2+60HOt8jpFUZDJZJDL5V6xl8/nY/369fj1r3+NuLg49PX14cyZM6iqqpp2HPlbhq+4uBj/+Z//iV/+8pfT/j4xMYG//vWvsNls0Ol0c9bl9fj7za2C6O/vj/Pnz+PSpUuzFm9z99W0Wq0YGBiYlwyJW5ll5cqVEIvFaG5uxqFDh1BVVXXTNxT5W7bHarXCZDKhrq7O6yvOFEUhPDwcCoVimodubW3FgQMHoNVqb7m6GRAQAD6fP+3/uVdHvYFly5YhLS0NcrkcFosFP//5z3Hq1KnrGgY7HA6MjIxg48aNEAgE12X0IiIi8G//9m8QCAT4y1/+gk8//XROdnmc+AqFAsnJyaBpGo2Njeju7p51V2SpVAoejwebzYbx8XGvE5/D4SA5ORlbt25FQEAACCFoaWnBwYMHodfrb7n7yN/fHzwejxXB8CZomoZSqYRCoWDLJ4ArYVdvby+qq6tvqSbC5XKxefNmxMbGTntwLBaL1+xXKpUICgpi50x1dXXQaDQzHutwONDZ2QkOhzPNPn9/f4SHhyM+Ph4ul4uVnpoLPB7qBAUFISUlBYQQNDY2zkrSB7hyY6OjoyESiWCxWDAxMeH10EEmkyErKwvbt28Hj8fD2NgYmpqacPr06VuSnsfjITg4mBWM83Z8zzAM4uPjr/PYU1NT6O3tRUNDww3fOO7VUaVSiR07diAxMZH9GyFkRsV3T4CiKERFRSE4OBhmsxl/+MMfoFarb/pdbu3gq48JCwtDfHw8pFIpTCYTTCbTnO316N1iGAZ+fn4IDg5mV2l7enpueZ5bBXHDhg0ICQnBxMTEvBR+3XPPPSgqKkJCQgKAK1mFioqKWy6M8Hg8qFQqJCYmQiqVsvZ7ExwOB1lZWZBIJNO8YVNTExtO3mi83CJ3P/zhD5GbmwuFQsH+zf2weGNyKxQKsW7dOqSlpUGn06GyshImk+m2rkHTNPLz87F161Y2ihgZGZlzmtujoY77lRQdHY3x8XFMTk7O6hUqEAiQmJiIxYsXw+FwsGWz3iQ+l8vFxo0bkZubC0IIDAYDDh48iIaGhpue5w45fvSjHyEpKQl8Ph8ajQbl5eVelfx0K4Vf+4D98Y9/RFVV1Q3DQoqisH79emzfvh1btmyBRCKZJrz25ptv4sSJEx6T4rna3qioKEgkEvT19aGysvKOQlcul8uK9FksFuzevRvd3d1zts+jxBcKhRCLxeDxeGhsbITFYpnVjxUKhUhJSYG/vz8uXbqEtrY2r9aKUxQFkUjELpPb7XZWQf1m9TZcLhcrV67EmjVrsGrVKohEIly8eBHHjh3D6OioV+ckLpcLQ0ND13k6q9UKu90+zUlcreu1YsUKbNy4EStXrmQ1fQHAZrOxD6xarfb4Q0vTNCIjI0FRFFpbW/HVV1/d0TUee+wxZGRkwGKx4NSpU6isrLzhHOF24FHi0zTNTkx6enpmFYcJBAIEBwcjJycHDMOgq6sLjY2NnjRrRvD5fFaB0Wazoa6ujl1DuBY0TYPP52PRokUoLS3F5s2bER8fD4fDgYsXL6KiosLruqwulwtjY2Pswh5FUSCEIDQ0FAEBAexxoaGh4PF4EIlEiI+Px86dO5Gbm4u4uLhp4nsGgwEXL15EbW2tV1Zs3XMSiqLYyfftnCsUCqFSqfDQQw8hPDwcXV1d2Lt3L1paWjwyH/Eo8d3aVhRFzbpgS6VSobi4GA8//DAmJiZQVVWFY8eOedKsGWG32+Hn5wexWAyz2Yzm5uYZwzKapiEUCrFo0SJ88skniI6OZsuSx8fHUVdXhwsXLnjdXpqmERAQMG1tg6IolJaWYnR0FPX19SCE4LHHHoNKpUJoaChWrVoFmUx23cTbYrGw5Q3e2onF5XKxdu1aAIDBYLitmNzPzw/p6enYtWsXEhMTUVVVhf379+ODDz7wmH0eJb5bINm924rP57OeaSb4+/tj69atePTRRyEUCvGTn/xkxhyvN8Dj8SAQCNgVULci+NWQSqVIS0tjwwU36c1mM5qamvDJJ5+gsrJyXhQGLRYL/vSnP2Hbtm1QKpWs946KikJ0dDRCQkLgcDhw7733IikpCX5+ftOElN1oamrCl19+iUOHDt2wpsdTsNvtCA0NxdKlS5GXl4fDhw/f8hyhUIiioiJs27YNCQkJ+P3vf4/du3fj3LlzHrXNo8S32WyYmpqCwWBAaGgoRCIRq216LdyTrpycHEgkElRVVaG2thZjY2OeNGlGEEJYJUaHwwEej4fc3FycOHECcrkcCoUCeXl5iIiIQEREBKKiohATEwMej4e2tjZcvHgR5eXlqK6uxuDg4Lys2Lrz124dYDehZTIZ1q9fj4iICADA4sWLERgYyDoh9+91x/Tvvfcezp49i87OTq8WANrtdpw6dQpZWVmIiorCsmXLbkp8mqYhEomwY8cOFBUVIT4+HgcOHMAXX3yB5ubm284G3QoeJ/7g4CBaW1sRHx+P8PBwDA0NTYshKYoCl8tFUFAQ1q1bh6ioKIyOjqKsrAz9/f1zq7G+DZjNZgwMDGB8fBxBQUFIT09HUVERLBYLwsPDUVpaisjISFaNHQDGxsZQU1ODgwcP4tChQ/Oy1nA1pqamcPnyZURFRbFEF4lEyMjIQGpqKqs2eTWsVitGR0cxODiItrY27Nu3b142nrjnPxaLBWFhYcjIyLjh5iKapiEWi5GZmYktW7YgKioKJpMJX375JWpqarzDidnWL2OWNdcRERHkvvvuI2azmfziF78ghYWFbC07RVGEz+eTiIgI8txzz5HR0VFy+vRp8vLLLxOBQHDb9d1ztffBBx8ku3fvJi6Xiz3P5XJN+7f7/1mtVvLRRx+R0tJSIhaL76jW3xNjXFRURN57773ravFngsvlIt3d3eSXv/wlWbVqFRGLxbfcY+upMaZpmsTFxZELFy4Qm81Genp6iEAguO77KYoiYrGYZGZmkosXLxK9Xk+OHDlCnn322du29TboTDxOfIZhSFRUFOns7CSjo6Pk008/JZs3byYqlYo8++yzZO/evWRgYICMj4+TsrIy8uCDD856s7ania9QKMizzz5LBgcHb3gdk8lE2tvbyU9/+lMSERFB+Hz+HdnqKeLz+Xxy3333kRMnThCbzXbdQ+qG1Wolly9fJs8++yxJT0+ftpFmvsaYy+WSY8eOkampKTI1NUX+8pe/kNzcXBIYGEg4HA4RCATk6aefJvv37yejo6PEarWS8+fPkyeeeIJIJBKvjLEbXtG59ff3x3PPPYfHH38cLpcLfX190Gq1iI6ORlBQEDgcDiorK/Hxxx+jsbERAwMDd5RZuJnps7GXy+UiMTER+fn5+P73v8+uQwgEAgwODuL06dPo6elBb28vamtr0d7ePqe4+FZDPdsxjo6ORlpaGtvzJzExETExMayKfHt7O2pra1FeXo6GhgaMjIzc8QR8LmNMURSefPJJbN26FWvWrMHIyAiampqg1WrZuqKUlBRERkbC398fnZ2dePXVV3HmzBl0dXXdURg523O8svvAbDbj66+/xpIlS7Bo0SLEx8dDJpOhp6cHg4ODGB4exr59+1BRUeHxScvtwG63o62tDePj44iPj4dQKIS/vz+EQiH6+vpw9OhRdHV1YWRkZM5lsJ6EWq2GRqNBe3s71Go1uzFFIBDAaDSisbER1dXVKC8vv6s9igghqKiogFgsRlhYGJYsWcKmON19crhcLvR6PTo7O3Ho0CEcOnQIY2NjXp87eVXZPCUlBVlZWVi+fDkKCwvx3//937h8+TImJibQ3Nx829e7FnP1+PMNT3n8+YQnxjgsLAxZWVl48803oVAorttEc/LkSTZPP9cNSLM916vEp2mazTRwOBz29UYI8cjyvo/43ocnxpiiKLZd4EznuDfzeGL95htBfG/DR3zv4+9tjN3wtQn3YUHCR3wfFiRmHer44MPfE3we34cFCR/xfViQ8BHfhwUJH/F9WJDwEd+HBQkf8X1YkJh1kdq3bZXu22Yv8O2z+dtm79XweXwfFiR8xPdhQcKnbO7DNx7uHkjujh3uJgFzgc/j+/CNRkBAAF566SXU1tais7MTtbW12LZtG3g83pyuO286ty+//DKUSiWEQiEsFgsuXLiAmpoaXLp0Cb29vXdNGfx2oFAosGzZMuTk5CA7OxsAUF5ejoqKCjQ1Nd1l6/6+wOFwIJVK8d///d9YuXIllEoluFwuJBIJtm/fDg6HM6ce+V4nfkhICNu6Q6lUsr0qQ0JCEB0djdTUVHZLosViYduR3M0tidfC3fNl48aNWLFiBdLT07F06VIAV7IITqcTly9fnrfWKLcCh8NhdzlJJBKIRCKIRCJIpVKYzWYMDQ15rYPaXMDhcKBQKBAaGoqwsDCoVCoUFhYiKCiI3dBE0zQiIiKgUqlu2qzslt/lYdungWEYJCUlobS0lG0w5e6vmZ2djezsbDgcDkxMTODUqVNsC8Hz58/j8uXL8664PRN4PB4kEgmioqLwgx/8ALGxsdN0ZVeuXAmKonDgwAH09/ffNVFqiqIgFArB4XAgkUjYrshRUVEskeLi4jA8PIzjx4+jrq7uG7OPmKIolvTZ2dlYuXIlcnJykJ6eDoqiYDQaodPpIJPJ2I53c9Uj8CrxY2JikJ2djVWrVkEsFl/3hLp/cHBwMLZt2wZCCO6//340NzfjV7/6Ffbt2weLxXJXw6DVq1djx44duPfee6FUKq9TBxSJRAgLC0NmZiar4jffoGkaCoUCP/zhD1nlEJVKBT8/P9A0zW73pCgKer0eKSkpOHz4MD788EOvN7udDSQSCRITE/Gzn/2MFaxmGAYulwtvvfUWjh07hsnJSWzatAnf+9730NHRgaampjnxwmvEpygK//iP/4jVq1dDpVKxmlEWiwV2ux1cLhdyuZxV3XOfIxaLsWTJEvz7v/87pqamUFNTg+HhYW+ZeVPweDxER0cjPT0dYWFhM0pi8vl8MAyD4eHhu+LtFQoFMjIyUFxcjIceegg8Hg98Ph8CgWBaVzU3SQICApCXlweFQgG73Y79+/dDq9XelQeWoijce++9KCwsxIoVK7B06VL2bWqz2TAxMYHdu3ejo6MDPB4Pra2tsNlsaGtrm/OcyivE53A4iIuLQ05ODhISEiASiWC327Fv3z5oNBpWslEqlUKhUEAulyMgIADBwcHsBCYxMRHZ2dno7e3FyMjIXfH6eXl5WLZsGaKiom6YRXC3EJfL5fMi93k1BAIBCgsLsWrVKuTl5bESmHa7HSaTCUNDQ+jt7YXJZILNZgNFUVi+fDmkUini4+NRWloKmqZRXV2N7u5u6PX6ebNdJBJh7dq12LhxIzIyMpCQkACJRAKdTgeLxQKdTof29nb09vZCq9XC39+fnfdZLJY5z6e8QnyBQIB77rkHSUlJkMvlsNvtUKvV+O1vf4vu7m7QNM0KFCckJCApKQnR0dGsJxIIBODz+cjJyUF1dTU6OzvnfeLIMAweeOABrF69GqGhodf93eVysUQXCoVITEzE8ePH581z0jSNwMBA3HfffcjJyUFERAQb0hgMBvT39+PYsWM4fvw4hoeHYTQaQdM0XnzxRSxduhRhYWEoLi5GdHQ0xGIxDh8+PG+ZKYZhoFAo8PzzzyMtLQ0ikYhtLd/R0YGJiQloNBpcuHABk5OTbM7e5XKBw+GAz+dfp9x425htyzXMsoWbUCgkycnJZGRkhDgcDmK320lrayuRSCSEpukZz6EoinA4HPLcc8+Rs2fPEqfTSQghxG63k//5n/8hxcXFXmkheKMPwzAkPDycdHZ2zthH02azEY1Gw9o5MjJC3n333Vu2vfPUGAMgAoGAbNmyhVy6dImYzWZit9uJwWAgw8PDpLy8nPzoRz+asVelXC4n69atIz//+c9JZ2cnsdvtpL29nfz6178mHA5nXsZYqVSSbdu2EYPBQJxOJ3E4HGRsbIz89a9/JcnJyUQmkxGJREIkEglrf1BQEHnkkUeIXq8nv/nNb0hhYeGcWgh61OPv2LED2dnZyMjIgEwmg81mwyeffIJdu3bdVCiCEAKHw4FPPvkESqWS/TAMA4FAME3e0pugKAoBAQFYvHgx3nzzTUREREwrxHI6ndi3bx/Ky8vR29uLDz/8EEFBQWz35/kKddwZkOeffx4RERFgGAZGoxGVlZX49NNP0dbWhoGBgRnlPycnJ3Hq1Ck0NjbiwIEDKCsrQ1hYGHJzc/Hwww/jk08+8ao+waOPPoqioiKsWLGCVbisq6tDZWUl/vjHP6Kvrw/AlXtxbWLDnRyRy+UIDg6ekx0eIz5FUcjOzkZBQQHi4uJgsVjw17/+Ffv27UNLS8usJn6jo6M4evQoxGIxHnvsMQiFQsTGxrKqhN5GbGwssrKyUFxcjJSUlGmTWYfDgdbWVjQ0NMz4e9zZk/lAVFQU8vPzsXjxYvB4POj1evT09GDPnj04c+YMRkdHb5itcTqdMBgMMJlM0Ol06O/vR1RUFPz8/BAYGOg1m7lcLtLS0rBhwwa2Z77NZsP+/ftx9uxZnD9/Hl1dXWzvf5qmr1tn8KTSvUeIT1EUqx6SlJQEoVCI5uZmvPnmm2hubp51toMQgsrKSthsNtx///2sGqJ7schbcIs1r1y5Etu2bcPGjRtZ0pO/iSoMDQ2xK7RTU1NIS0sDn89nCT8fKi7AlSxScnIyduzYgcDAQGi1WnR1deHcuXPYu3cvdDrdrMbb5XKxyi5SqRQAvLZuIhQKERISgi1btqCwsBDBwcFwOp0YGxvDH/7wB1y8eBEajYa1eyb7eTweFAoFaJqG3W7/Zsh9CgQCPPDAA0hISIBQKMTAwAAeeOAB9PX13baBbkUVN8RiMfz8/Dxh5g0hEonwxBNP4Pnnn58ms0MIgdVqxeXLl/HMM8+guroaLpcLsbGx2LRpExuCuUO1+fD4S5cuxZo1a7B+/XoAwF/+8heUlZWhqqpq2rjNBi6XCx999BGCgoKgUCgwPj7uld+watUqPPXUU9iyZQs4HA6rXF9WVoaLFy/eMmvH5XKhUqnw3HPPQSQSsS0H54I5Ez80NBTLli3Dj3/8YygUChw5cgRvv/02ent779gLulwu9qkXiUQQi8VzNfOG4PP5iIiIwDPPPIPg4GCW9Ha7HR9++CGqq6tRX19/nThcUlIS+1Ywm81obW31ukSpRCLBP/7jP6KoqAgulwsNDQ344IMP0NLSckdZL0IIRkdH2WpHvV7vceLn5ORg7dq1KCoqApfLxdTUFL744gu8++676OjomFVn5ODgYMTGxkIul2NqagoXL17E+fPn52TXnIkfERGBkpIShISEYGBgAI2Njbhw4cIdk95d0nC1fpO3QNM00tLSsH37doSHh4PL5cLlcsFgMKCiogL79u1Da2srhoeHWWJxuVxwOBxWHgi4EiK441NvgcPhYPny5UhNTUVQUBAmJyexd+9e9PX13XFdE8MwWLNmDeRyObRaLXp6ejw63gzDIDU1FUlJSWw4VVtbi+rqajQ1NWFycvKW1xCJRFi5ciXWrl0LhmFQVVWFtra2WZ17M8yJ+G51w6KiIgDAxYsXUV9fP6eVVoZhwDAM613NZrPXCtbcIm+PPfYYmxc2mUxQq9X485//zIYPV5OBw+FMU0h0uVwwGo3o6Ojw6sotl8tFSUkJVCoVOBwO+vr6sH///jtedHIvvG3YsAFCoRBNTU3o6+vz2G+gaRoqlQrLli1DXFwcGIZhHcrFixdnJVTBMAwiIiJQVFSE4uJiOBwOHDlyZNYayjfDnIjP4XAgl8uxaNEi2Gw2vPHGG3OWZXTX9Jw/fx7r169HW1ub1wSfH3nkEZSWliIoKAjAlbdLZ2cnDh48iM8++2xG78fj8eDv74/Q0FAwDAO9Xg+1Wo3q6mqvvp0EAgEeeeQRyGQyVjC5vr7+jq/H4/EQFhaGmJgY7N+/H3v37vXoIqGfnx/efPNNdqXYarWisrISv//979HT03PL893ceuSRR7By5UrIZDIMDw/jwoULHlHGnBPxf/CDH2Djxo2gKAoTExPQ6/VzfhJzc3NRWlqKgoICcDgcVFRU4MCBA3O65rWgKAp+fn7Izc3FokWL2DTZyMgIjh07hvfff/+GpN+5cye++93vQiAQAAAGBgZw+fJlj9p3LSIjI7Fq1SrI5XIAwNmzZ7Fr1647uhZN09iyZQvWr1+P/Px8TExMoLa21qOrtlKpFElJSVi+fDkkEglcLhdGR0fxL//yL7OKBvh8PhISEvCLX/yClYNtbm7Gk08+iebm5ruvbL548WLExcWBEIKRkRHY7fY5eT2lUonU1FSkpaXBz8+PleQcGBiYi5nXgaZpREZGIiwsjI09gSskdu8NuBoURYHP5+Phhx9GaWkpkpOTAVwppGppacGFCxe86u2VSiWKiorA4XAwMDAAtVp9W2NCURQEAgGUSiWio6OxZs0aZGdng8fj4Q9/+APOnz+PiYkJj9mrUqmwefNmiMViMAyD+vp67N+/H4ODgzPOg66utU9ISEBGRgaWL1+OzMxMBAYG4vz58ygvL0d7e7vHqknnRPyQkBDI5XKW+Hf6JDIMA6lUipycHGRkZCAmJgY0TePy5csYGBjwuHI4h8NBZmYmQkJCWM9NCEFLSwt6enrYVz7DMAgMDIRcLodQKMRDDz2ElJQUNjRqbW1FdXU1Ll686FH7rkVgYCAWL14MiqIwMjICjUYz67CEYRj4+fkhNDQUBQUFSElJQUZGBsRiMerq6rBnzx709fV5jFA0TSM6Ohpr164Fh8MBIQTNzc3485//PI307s09wcHBEAgEbNIgPz8fxcXFyM3NhUKhQH9/P44fP46DBw/edrr2ZpgT8QUCAXg8HqxWK9Rq9R1ncqRSKUpLS/HCCy8gOjoaEokEdrsdv/3tb3H+/HmP14wLhUI899xzUCqV07JH10rH+/v74zvf+Q7uv/9+9mFxT4JdLheefvrpWWcn5gKn08k6FY1GA61WO6sePQzDwN/fH9nZ2SgpKcH3v/99MAyDtrY2HD16FK+88gp6eno8OikXCoVQKpVIS0sDcOWtODIygra2tml2uQWd3WlkLpcLgUCARYsWsZWwLpcLr732Gr7++mv2fE9hTsS3WCyw2WxgGAZxcXGs95wt4uLisHbtWpSUlLATGJqm0d/fj48//hhffPGFV0jlDnWuHmCtVovx8XGYzWaIRCKsWLECL730EhITExEYGAiaptkUpsViQWdn57wpsU9OTqK9vR333HMPMjMz0d7ejqqqKnaS6NaYEolESEhIYCteMzMz2VSiUCiE0+nE448/josXL2JwcBAmk8njmSiFQgGZTMaOlc1mQ35+Pt59910EBwcjMjISYrEYPB6PlVd1z7HcG5MIIRgfH8fevXuxe/dujIyMeNRGYI7EJ38rg2UYBomJiQgKCoJarWbJcPWOK4qikJaWhqCgIAQEBCAsLAxJSUlYsmQJ4uLiIJfL4XK5UF9fj9OnT7PL796Qq3Qv3EgkEnA4HFAUBS6Xi+3bt6OkpARSqRQxMTFISUmBv78/ezOsVisaGhpQU1ODEydOYGxsbF7kNEdGRnDu3Dk89dRTkEqlKCoqgkAgQHl5OSwWC6Kioth9D3K5nP0EBwcjICAA7e3taGxsxLlz53Dq1Kmb1vLMFREREQgJCWF3fAkEAsTExEAul0MkEsHPzw9cLnfa9kFCCEwmE86dO4eGhgZoNBpoNBq0tbVhdHTUK+UgcyK+TqeD0WiEQqFAeHg4li1bBg6HA71eDx6PB5qmp3mU1atXQ6lUshvN3dvjOBwOJicncfnyZRw/fhyVlZWoq6vzWv2Ly+XC+Pg4IiMjAfzv5HXt2rUQCARQKBTsTiCHwwGdTsfq81ZWVqKyshInT56cNw3ZiYkJNDY2QqPRQC6XY/HixYiMjISfnx+mpqaQkJCA1NRUdn3BHRpNTk6ipaUFVVVVOH78OI4ePQqz2ezVibjbe1utVvB4PHA4HAQGBiIwMJCtaXKvFLtcLgwPD8NkMmFsbAzl5eU4efIk1Go1tFqtV+uf5kT8c+fOISQkBKtXrwaHw8F//Md/wGg0wmazITo6mn0jkL91IuDxeOzs3f02cDqdmJiYwNGjR/H666+jq6vL65ug3TfgagLw+XwsXrx42nEOhwOjo6NoaWnBG2+8gSNHjtyVPapGo5EVQC4uLmY9+YMPPjitrsjlcsFqtWJ4eBidnZ04fPgwjh8/jt7eXq/V4VyLc+fOISoqCps3b2Z3pVEUBYqiYLVaodFoMDY2hvHxcVitVrz99ttoaWnB0NDQvG7dnBPx9Xo9xsfHodVq2afaXdp6s9p092rn+fPnsXfvXhw9ehS9vb0wm83z0vLC4XDg5MmT7Ha3a5ufuisHP//8c1RVVaGmpgYDAwPzVoF5LQgh0Ov1ePbZZ5Gbm4s1a9Zg3bp1EIlEEAgEGB4eRnt7O86dOweHw4H29na0tLRgdHQUNpsNLpdr3kqmrVYrysvL0draylaPule7NRrNdTZZLBY4nc5531o6J+KfOHECExMT6OrqQkFBAQYHB0HTNKRSKSIiIgBcmZhpNBr2OPcboLu7GyMjI+jp6cHQ0NC89tGx2Ww4dOgQsrKywDAMQkJCQNM0hoaGUF1djaqqKuj1ejQ2NmJgYABjY2N3jfRuEEKg0+lQW1vLhlwcDgcMw2Bqago6nQ4ajQbAlRBUp9PdlQ3k5G9NBdyhjnuvr7sMxWKx3LUWLFdjTgLP7r2TcXFxKCoqQk9PDxiGgUwmg0qlAnAlPh0aGsLIyAiam5vZc7u7u+fs3W9m+s1aWLt3Wv3DP/wDli5divDwcDabdPz4cRw6dAgWiwV6vd6jb6DZpCC/abjTMb5bmO2bw6dsPo/wEd/7mC3xfU1jfViQ8BHfhwUJH/F9WJDwEd+HBYlZT2598OHvCT6P78OChI/4PixI+Ijvw4KEj/g+LEj4iO/DgoSP+D4sSPiI78OChI/4PixI+Ijvw4LE/wctWbYpR/1AfQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 220x220 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = load_model('cgan_mnist.h5')\n",
    "test_generator(gen, 0)\n",
    "#test_generator(gen, 1)\n",
    "#test_generator(gen, 2)\n",
    "#test_generator(gen, 3)\n",
    "#test_generator(gen, 4)\n",
    "#test_generator(gen, 5)\n",
    "#test_generator(gen, 6)\n",
    "#test_generator(gen, 7)\n",
    "#test_generator(gen, 8)\n",
    "#test_generator(gen, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to train the model, uncomment the following line\n",
    "#build_and_train_models()\n",
    "#that will take a long time to run, so be prepared, and make sure you have a GPU available\n",
    "#you can also run the code in a cloud environment like Google Colab\n",
    "#https://colab.research.google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc390f22",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we implemented and trained a CGAN on the MNIST dataset. By conditioning the generator and discriminator on labels, we are able to generate specific digits based on the input label.\n",
    "\n",
    "`python cgan-mnist.py --generator=cgan_mnist.h5 --digit=6`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935f5e6",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
